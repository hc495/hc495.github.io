---
layout: page
permalink: /phd_defense
title: "Ph.D. Dissertation: The Mechanistic Basis of In-context Learning"
---

This dissertation is composed of the following 4 peer-reviewed top-tier international conference papers. Notice that the author use the name Hakaze Cho in his publications.

Refer the [main page](https://www.hakaze-c.com/){:target="_blank"} for more publication details.

- Chapter 3: [Revisiting In-context Learning Inference Circuit in Large Language Models](https://openreview.net/forum?id=xizpnYNvQq){:target="_blank"} (ICLR 2025 Poster) [h5=362, IF=48.9, Core A*]
- Chapter 4: [Mechanism of Task-oriented Information Removal in In-context Learning](https://arxiv.org/abs/2509.21012){:target="_blank"} (ICLR 2026 under review, rating 7.5 (10, 10, 6, 4), top 0.1%) [h5=362, IF=48.9, Core A*]
- Chapter 5: [Token-based Decision Criteria Are Suboptimal in In-context Learning](https://aclanthology.org/2025.naacl-long.278/){:target="_blank"} (NAACL 2025 Long Paper) [h5=126, IF=16.5, Core A]
- Chapter 6: [Mechanistic Fine-tuning for In-context Learning](https://arxiv.org/abs/2505.14233){:target="_blank"} (BlackboxNLP Workshop at EMNLP 2025)

## Resources for Preliminary Defense

### Dissertation

**2025/11/24 Revision**

<span style='color:red'>The full dissertation with supplementary materials (Preliminary Defense version, 2025/11/24 revised):</span> [PDF](https://jstorage.box.com/s/0ieqpurrjqm3a0h3nxlquzuhrc5vud6j){:target="_blank"}

Revision Note:

- Merged the ICLR 2026 rebuttal revision into the Chapter 4. See [OpenReview](https://openreview.net/forum?id=VAv1rrPR1A&noteId=iSaPWnf9bw){:target="_blank"} "Revision Note 2025/11/20 (AOE)" for details.
- Removed some of previous works.
- Revised the title of one committee member.
- Fixed two writting issues in the Abstract section.
- Fixed one writting issue in Acknowledgement section.
- Revised some content in Acknowledgement section.
- Improved the clarity of Abstract section.
- Fixed one \ref issue in Appendix A.
- Unified the name of LMs across diffenerent Chapters. The new name is something like Name-Scale (e.g., GPT 2-Small, Llama 2-7B, etc.)
- Some adjustments on the layout of Chapter 6 to improve aesthetic.
- Unified the color of all hyperlink to #028390.

**2025/10/30 Original**

The full dissertation with supplementary materials (Preliminary Defense version, original): [Old Version Download Closed]

### Presentation Slides

The slides for the Preliminary Defense: TBA

## Other Online Resources

The source codes for every experimental chapter are available at the following GitHub repositories: 

- Chapter 3: [GitHub: ICL_Circuit](https://github.com/hc495/ICL_Circuit){:target="_blank"}
- Chapter 4: [GitHub: Verb_subspace](https://github.com/hc495/Verb_subspace){:target="_blank"} (TBA)
- Chapter 5: [GitHub: Hidden_Calibration](https://github.com/hc495/Hidden_Calibration){:target="_blank"}
- Chapter 6: [GitHub: ICL_head_tuning](https://github.com/hc495/ICL_head_tuning){:target="_blank"}