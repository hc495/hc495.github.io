---
layout: page
permalink: /
title: "Hakaze Cho / Yufeng Zhao / 趙 羽風"
---

<div class="img_margin">
<img src="./assets/fig/photo.png" alt="" title="@Beijing Inst. Tech. 2023" height="240">
<figcaption>@ICLR 2025</figcaption>
</div>

**Ph.D. 3rd Year Student** @ [Graduate School of Information Science](https://www.jaist.ac.jp/areas/cs/){:target="_blank"}, [Japan Advanced Institute of Science and Technology](https://www.jaist.ac.jp/){:target="_blank"}  
**Fully-funded Research Assistant** @ [RebelsNLU](https://rebelsnlu.super.site/){:target="_blank"}, PI: [Assoc. Prof. Naoya Inoue](https://naoya-i.info/){:target="_blank"}   

**Alias**: Yufeng Zhao, both from the hieroglyph “趙 羽風”  
**Birth**: Beijing, 1999
<!-- **Affiliation**: Japan Advanced Institute of Science and Technology ← Beijing Institute of Technology   -->

### Contact

[Twitter](https://x.com/yfZhao495){:target="_blank"} &nbsp;&nbsp;&nbsp;
[GitHub](https://github.com/hc495){:target="_blank"} &nbsp;&nbsp;&nbsp; 
[OpenReview](https://openreview.net/profile?id=%7EHakaze_Cho1){:target="_blank"} &nbsp;&nbsp;&nbsp;
[ORCID](https://orcid.org/0000-0002-7127-1954){:target="_blank"} &nbsp;&nbsp;&nbsp;
[CV](./assets/cv_yfzhao.pdf){:target="_blank"}    
**Physical Address**: Laboratory I-52, Information Science Building I, 1-1 Asahidai, Nomi, Ishikawa, Japan   
**E-mail**: yfzhao [at] jaist.ac.jp  
This email address is not always reachable. If I do not reply, please try CC the message to yfZhao495 [at] outlook.com.  

### Biography

I, aka Yufeng Zhao, graduated from Beijing Institute of Technology, a top-ranking university in China, with a Master's degree in Software Engineering in 2023 and a Bachelor's degree in Chemistry in 2021. I am in my graduation thread of Ph.D. at JAIST with a fast-track schedule in March 2026. My research focuses on exploring the internal mechanisms of artificial neural networks, particularly Transformer-based neural language models, during both training and inference, by mathematical and representation learning methods, and improving their performance robustly through our deeper understanding. I have published over 30 papers / presentations in this area since 2023, some of which have been presented at top-tier international conferences such as ICLR and NeurIPS.

**Research Collaboration Statement.** I am actively seeking productive research collaborations in the mentioned area. If you are interested in working together on top conference papers, please do not hesitate to contact me. I welcome collaborations with both experts and motivated beginners—being a novice is not a drawback if you are eager and efficient to learn. Additionally, I am open to exploring collaborations in other areas as well. 

**Position Interests.** I have already signed a full-time contract starting in April 2026, and I welcome visiting and part-time positions. At the same time, I am seeking an associate professor position starting in April 2029.

## Research Interests

**Keywords**: Representation Learning, Mechanistic Interpretability, In-context Learning  
- **Interpretability for Artificial Neural Network**: Mechanistic interpretability (especially for Transformer)   
  [[ICLR 2025](https://openreview.net/forum?id=xizpnYNvQq){:target="_blank"}] [[NeurIPS 2025](https://openreview.net/forum?id=FIfjDqjV0B){:target="_blank"}] [[COLING 2025](https://aclanthology.org/2025.coling-main.708/){:target="_blank"}]
- **Controllability for Artificial Neural Network**: Low-resource model behavior improvement / controlling from mechanistic perspective  
  [[NAACL 2025](https://aclanthology.org/2025.naacl-long.278/){:target="_blank"}] [[BlackboxNLP 2025](https://aclanthology.org/2025.blackboxnlp-1.21/){:target="_blank"}] 
- **Misc.**: Manifold Learning, Low-precision Neural Networks, Neural Network Training Dynamics  
  [[ArXiv](https://arxiv.org/abs/2509.20997){:target="_blank"}] [[ArXiv](https://arxiv.org/abs/2503.02142){:target="_blank"}]

## Publications

[[Export Publication List as TXT](/subpages/export.html?action=exportPaper){:target="_blank"}] 
[[Google Scholar](https://scholar.google.com/citations?user=q_eQAcwAAAAJ){:target="_blank"}] 
[[Researchmap](https://researchmap.jp/hc495?lang=en){:target="_blank"}] 
[[Semantic Scholar](https://www.semanticscholar.org/author/Hakaze-Cho/2304519017){:target="_blank"}] 
[[DBLP](https://dblp.org/pid/379/4520.html){:target="_blank"}]   
{% include_relative _includes/paper_statics.html %}

### International Conference

{% include_relative _includes/paper_list_international_c_papers.html %}

### Pre-print

{% include_relative _includes/paper_list_pre_print_papers.html %}

<!-- ### <a title="(† = Japan-domestic Secondary Publication for Conference Papers; Default: Non-refereed,▲= Refereed)">Domestic Conferences / Miscellaneous</a><br><span style="font-size:0.8em">(† = Japan-domestic Secondary Publication for International Conference Papers; Default: Non-refereed,▲= Refereed)</span> -->

### Domestic Conferences / Journal / Miscellaneous<br><span style="font-size:0.8em">(† = Japan-domestic Secondary Publication for International Conference Papers; Default: Non-refereed, ▲= Refereed)</span>

{% include_relative _includes/paper_list_domestic_c_papers_en.html %}


### (Thesis)

1. **The Mechanistic Basis of In-context Learning**    
    Yufeng Zhao   
    Ph.D. Dissertation @ Japan Advanced Institute of Science and Technology. **2026**. 223 pages.
2. **Fine-tuning with Randomly Initialized Downstream Network: Finding a Stable Convex-loss Region in Parameter Space**    
    Yufeng Zhao   
    Master's Thesis - Rank A @ Beijing Institute of Technology. **2023**. 81 pages.
3. **Synthesis and Self-Assembly of Aggregation-induced Emission Compounds**   
   Yufeng Zhao   
   Bachelor Thesis @ Beijing Institute of Technology. **2021**. 52 pages.

## Resume

<!-- <div class="img_margin" style="display: flex; align-items: center; gap: 10px;">
    <img src="./assets/fig/jaist.png" height="105">
    <img src="./assets/fig/bit_xiaohui.jpg" height="150">
</div> -->

- **[Special Postdoc Research Fellowship](https://www.riken.jp/en/careers/programs/spdr/){:target="_blank"}** (SPDR), (2026.4) ~ (2029.3)  
  [Natural Language Understanding Team](https://aip.riken.jp/labs/goalorient_tech/nat_lang_understand/?lang=en){:target="_blank"}, [Center for Advanced Intelligence Project (AIP)](https://aip.riken.jp/labs-list/?lang=en){:target="_blank"}, [RIKEN](https://www.riken.jp/en/){:target="_blank"}, Japan  
  Mentor: [Prof. Kentaro Inui](https://kentaro-inui.github.io/){:target="_blank"}
- **Postdoctoral Researcher** (2026.4) ~ (2029.3)  
  [Tohoku NLP Group](https://www.nlp.ecei.tohoku.ac.jp/about-us/members/){:target="_blank"}, [Tohoku University](https://www.tohoku.ac.jp/en/){:target="_blank"}, Japan  
  Mentor: [Prof. Kentaro Inui](https://kentaro-inui.github.io/){:target="_blank"}
- **Ph.D.** in Computer Science, Research Assistant, 2023.10 ~ (2026.3), Fast-track Graduation  
  [Graduate School of Information Science](https://www.jaist.ac.jp/areas/cs/){:target="_blank"}, [Japan Advanced Institute of Science and Technology](https://www.jaist.ac.jp/){:target="_blank"}, Japan  
  Mentor: [Assoc. Prof. Naoya Inoue](https://naoya-i.info/){:target="_blank"}
- **M.Eng.** in Software Engeering, 2021.9 ~ 2023.6   
  [Graduate School of Computer Science and Technology](https://cs.bit.edu.cn/){:target="_blank"}, [Beijing Institute of Technology](https://www.bit.edu.cn/){:target="_blank"}, China   
  Mentor: Yufeng Zhao (Self-motivated)
- **B.Eng.** in Chemistry, 2017.8 ~ 2021.6  
  [School of Material Science and Engineering](https://mse.bit.edu.cn/){:target="_blank"}, Department of Basic Science, [Beijing Institute of Technology](https://www.bit.edu.cn/){:target="_blank"}, China   
  Mentor: [Assoc. Prof. Jianbing Shi](https://pure.bit.edu.cn/en/persons/jianbing-shi/){:target="_blank"}

## Professional Activities

### Peer Review

{% include_relative data/review_list.md %}

### Society Member

- Student Member, The Japanese Association for Natural Language Processing
- Student Member, The Japanese Society for Artificial Intelligence
- Association for Computational Linguistics (ACL)

### Grants

- **Principal Investigator**: Towards Mechanistic Controllability: Circuit-based Behavior Correction for Large Language Models   
  RIKEN SPDR Grant, 2026.4 ~ 2029.3, JPY 3,000,000.

### Awards

- [Outstanding Paper](https://anlp.jp/nlp2025/award.html#outstanding){:target="_blank"} @ The 31st Annual Conference of the (Japanese) Association for Natural Language Processing (NLP2025, ANLP). 2025. (top 14 in 765, 2.0%)
- [Research Award for Young Scholars](https://sites.google.com/sig-nl.ipsj.or.jp/sig-nl/%E6%8E%88%E8%B3%9E/young#h.qq15e8v12s8d){:target="_blank"} @ The 260th SIG for Natural Language, Information Processing Society of Japan (SIG-NL260, IPSJ). 2024.
- [SB Intuitions Awards](https://www.anlp.jp/nlp2024/award.html){:target="_blank"} @ The 30st Annual Conference of the Japanese Association for Natural Language Processing (NLP2024, ANLP). 2024.
- Monbukagakusho Honors Scholarship @ Japanese Ministry of Education, Culture, Sports, Science and Technology. 2023.
- Outstanding Oral Presentation @ 2022 Euro-Asia Conference on Frontiers of Computer Science and Information Technology. 2022.
- GPA Improvement Award @ Beijing Institute of Technology. 2020. <small>I missed (medical) many exams in 2019, so my regular GPA in 2020 were considered a significant improvement.</small>
- Annual Outstanding Academic (GPA) Scholarship @ Beijing Institute of Technology. 2018, 2019, 2021, 2022, 2023.
- First Prize @ 30th Chinese (High School) Chemistry Olympiad. 2016.
- Second Prize @ 29th Chinese (High School) Chemistry Olympiad. 2015.