---
layout: page
permalink: /
title: "Hakaze Cho / Yufeng Zhao / 趙 羽風"
---

{%- if site.photo-path -%}
<div class="img_margin">
<img src="{{ site.photo-path }}" alt="" height="240">
<figcaption>{{ photo-caption }}</figcaption>
</div>
{%- else -%}
{%- endif -%}

**Ph.D. 3rd Year Student** @ [Graduate School of Information Science](https://www.jaist.ac.jp/areas/cs/){:target="_blank"}, [Japan Advanced Institute of Science and Technology](https://www.jaist.ac.jp/){:target="_blank"}  
**Fully-funded Research Assistant** @ [RebelsNLU](https://rebelsnlu.super.site/){:target="_blank"}, PI: [Assoc. Prof. Naoya Inoue](https://naoya-i.info/){:target="_blank"}   
{:.lang .lang-en}

**Alias**: Yufeng Zhao, both from the hieroglyph “趙 羽風”  
**Birth**: Beijing, 1999
{:.lang .lang-en}

### Contact
{:.lang .lang-en}

[Twitter](https://x.com/yfZhao495){:target="_blank"} &nbsp;&nbsp;&nbsp;
[GitHub](https://github.com/hc495){:target="_blank"} &nbsp;&nbsp;&nbsp; 
[OpenReview](https://openreview.net/profile?id=%7EHakaze_Cho1){:target="_blank"} &nbsp;&nbsp;&nbsp;
[ORCID](https://orcid.org/0000-0002-7127-1954){:target="_blank"} &nbsp;&nbsp;&nbsp;
[CV](./assets/cv_yfzhao.pdf){:target="_blank"}    
**Physical Address**: Laboratory I-52, Information Science Building I, 1-1 Asahidai, Nomi, Ishikawa, Japan   
**E-mail**: yfzhao [at] jaist.ac.jp  
This email address is not always reachable. If I do not reply, please try CC the message to yfZhao495 [at] outlook.com.  
{:.lang .lang-en}

### Biography
{:.lang .lang-en}

I, aka Yufeng Zhao, graduated from Beijing Institute of Technology, a top-ranking university in China, with a Master's degree in Software Engineering in 2023 and a Bachelor's degree in Chemistry in 2021. I am in my graduation thread of Ph.D. at JAIST with a fast-track schedule in March 2026. My research focuses on exploring the internal mechanisms of artificial neural networks, particularly Transformer-based neural language models, during both training and inference, by mathematical and representation learning methods, and improving their performance robustly through our deeper understanding. I have published over 30 papers / presentations in this area since 2023, some of which have been presented at top-tier international conferences such as ICLR and NeurIPS.
{:.lang .lang-en}

**Research Collaboration Statement.** I am actively seeking productive research collaborations in the mentioned area. If you are interested in working together on top conference papers, please do not hesitate to contact me. I welcome collaborations with both experts and motivated beginners—being a novice is not a drawback if you are eager and efficient to learn. Additionally, I am open to exploring collaborations in other areas as well. 
{:.lang .lang-en}

**Position Interests.** I have already signed a full-time contract starting in April 2026, and I welcome visiting and part-time positions. At the same time, I am seeking an associate professor position starting in April 2029.
{:.lang .lang-en}

## Research Interests
{:.lang .lang-en}

**Keywords**: Representation Learning, Mechanistic Interpretability, In-context Learning  
{:.lang .lang-en}

- **Interpretability for Artificial Neural Network**: Mechanistic interpretability (especially for Transformer)   
  [[ICLR 2025](https://openreview.net/forum?id=xizpnYNvQq){:target="_blank"}] [[NeurIPS 2025](https://openreview.net/forum?id=FIfjDqjV0B){:target="_blank"}] [[COLING 2025](https://aclanthology.org/2025.coling-main.708/){:target="_blank"}]
- **Controllability for Artificial Neural Network**: Low-resource model behavior improvement / controlling from mechanistic perspective  
  [[NAACL 2025](https://aclanthology.org/2025.naacl-long.278/){:target="_blank"}] [[BlackboxNLP 2025](https://aclanthology.org/2025.blackboxnlp-1.21/){:target="_blank"}] 
- **Misc.**: Manifold Learning, Low-precision Neural Networks, Neural Network Training Dynamics  
  [[ArXiv](https://arxiv.org/abs/2509.20997){:target="_blank"}] [[ArXiv](https://arxiv.org/abs/2503.02142){:target="_blank"}]
{:.lang .lang-en}

## Publications
{:.lang .lang-en}

[[Export Publication List as TXT](/subpages/export.html?action=exportPaper){:target="_blank"}] 
[[Google Scholar](https://scholar.google.com/citations?user=q_eQAcwAAAAJ){:target="_blank"}] 
[[Researchmap](https://researchmap.jp/hc495?lang=en){:target="_blank"}] 
[[Semantic Scholar](https://www.semanticscholar.org/author/Hakaze-Cho/2304519017){:target="_blank"}] 
[[DBLP](https://dblp.org/pid/379/4520.html){:target="_blank"}]   
{% include_relative _includes/paper_statics.html %}
{:.lang .lang-en}

### International Conference
{:.lang .lang-en}

{% include_relative _includes/paper_list_international_c_papers.html %}
{:.lang .lang-en}

### Pre-print
{:.lang .lang-en}

{% include_relative _includes/paper_list_pre_print_papers.html %}
{:.lang .lang-en}

### Domestic Conferences / Journal / Miscellaneous<br><span style="font-size:0.8em">(† = Japan-domestic Secondary Publication for International Conference Papers; Default: Non-refereed, ▲= Refereed)</span>
{:.lang .lang-en}

{% include_relative _includes/paper_list_domestic_c_papers_en.html %}
{:.lang .lang-en}

### Thesis
{:.lang .lang-en}

1. **The Mechanistic Basis of In-context Learning**    
    Yufeng Zhao   
    Ph.D. Dissertation @ Japan Advanced Institute of Science and Technology. **2026**. 223 pages.
2. **Fine-tuning with Randomly Initialized Downstream Network: Finding a Stable Convex-loss Region in Parameter Space**    
    Yufeng Zhao   
    Master's Thesis - Rank A @ Beijing Institute of Technology. **2023**. 81 pages.
3. **Synthesis and Self-Assembly of Aggregation-induced Emission Compounds**   
   Yufeng Zhao   
   Bachelor Thesis @ Beijing Institute of Technology. **2021**. 52 pages.
{:.lang .lang-en .wide_list}

## Resume
{:.lang .lang-en}

- **[Special Postdoc Research Fellowship](https://www.riken.jp/en/careers/programs/spdr/){:target="_blank"}** (SPDR), (2026.4) ~ (2029.3)  
  [Natural Language Understanding Team](https://aip.riken.jp/labs/goalorient_tech/nat_lang_understand/?lang=en){:target="_blank"}, [Center for Advanced Intelligence Project (AIP)](https://aip.riken.jp/labs-list/?lang=en){:target="_blank"}, [RIKEN](https://www.riken.jp/en/){:target="_blank"}, Japan  
  Mentor: [Prof. Kentaro Inui](https://kentaro-inui.github.io/){:target="_blank"}
- **Postdoctoral Researcher** (2026.4) ~ (2029.3)  
  [Tohoku NLP Group](https://www.nlp.ecei.tohoku.ac.jp/about-us/members/){:target="_blank"}, [Tohoku University](https://www.tohoku.ac.jp/en/){:target="_blank"}, Japan  
  Mentor: [Prof. Kentaro Inui](https://kentaro-inui.github.io/){:target="_blank"}
- **Ph.D.** in Computer Science, Research Assistant, 2023.10 ~ (2026.3), Fast-track Graduation  
  [Graduate School of Information Science](https://www.jaist.ac.jp/areas/cs/){:target="_blank"}, [Japan Advanced Institute of Science and Technology](https://www.jaist.ac.jp/){:target="_blank"}, Japan  
  Mentor: [Assoc. Prof. Naoya Inoue](https://naoya-i.info/){:target="_blank"}
- **M.Eng.** in Software Engeering, 2021.9 ~ 2023.6   
  [Graduate School of Computer Science and Technology](https://cs.bit.edu.cn/){:target="_blank"}, [Beijing Institute of Technology](https://www.bit.edu.cn/){:target="_blank"}, China   
  Mentor: Yufeng Zhao (Self-motivated)
- **B.Eng.** in Chemistry, 2017.8 ~ 2021.6  
  [School of Material Science and Engineering](https://mse.bit.edu.cn/){:target="_blank"}, Department of Basic Science, [Beijing Institute of Technology](https://www.bit.edu.cn/){:target="_blank"}, China   
  Mentor: [Assoc. Prof. Jianbing Shi](https://pure.bit.edu.cn/en/persons/jianbing-shi/){:target="_blank"}
{:.lang .lang-en .wide_list}

## Professional Activities
{:.lang .lang-en}

### Peer Review
{:.lang .lang-en}

{% include_relative data/review_list.md %}
{:.lang .lang-en}

### Society Member
{:.lang .lang-en}

- Student Member, The Japanese Association for Natural Language Processing
- Student Member, The Japanese Society for Artificial Intelligence
- Association for Computational Linguistics (ACL)
{:.lang .lang-en}

### Grants
{:.lang .lang-en}

- **Principal Investigator**: Towards Mechanistic Controllability: Circuit-based Behavior Correction for Large Language Models   
  RIKEN SPDR Grant, 2026.4 ~ 2029.3, JPY 3,000,000.
{:.lang .lang-en}

### Awards
{:.lang .lang-en}

- [Outstanding Paper](https://anlp.jp/nlp2025/award.html#outstanding){:target="_blank"} @ The 31st Annual Conference of the (Japanese) Association for Natural Language Processing (NLP2025, ANLP). 2025. (top 14 in 765, 2.0%)
- [Research Award for Young Scholars](https://sites.google.com/sig-nl.ipsj.or.jp/sig-nl/%E6%8E%88%E8%B3%9E/young#h.qq15e8v12s8d){:target="_blank"} @ The 260th SIG for Natural Language, Information Processing Society of Japan (SIG-NL260, IPSJ). 2024.
- [SB Intuitions Awards](https://www.anlp.jp/nlp2024/award.html){:target="_blank"} @ The 30st Annual Conference of the Japanese Association for Natural Language Processing (NLP2024, ANLP). 2024.
- Monbukagakusho Honors Scholarship @ Japanese Ministry of Education, Culture, Sports, Science and Technology. 2023.
- Outstanding Oral Presentation @ 2022 Euro-Asia Conference on Frontiers of Computer Science and Information Technology. 2022.
- GPA Improvement Award @ Beijing Institute of Technology. 2020. <small>I missed (medical) many exams in 2019, so my regular GPA in 2020 were considered a significant improvement.</small>
- Annual Outstanding Academic (GPA) Scholarship @ Beijing Institute of Technology. 2018, 2019, 2021, 2022, 2023.
- First Prize @ 30th Chinese (High School) Chemistry Olympiad. 2016.
- Second Prize @ 29th Chinese (High School) Chemistry Olympiad. 2015.
{:.lang .lang-en}






**博士後期課程3年生** @ [北陸先端科学技術大学院大学](https://www.jaist.ac.jp/){:target="_blank"}, [コンピューティング科学研究領域](https://www.jaist.ac.jp/areas/cs/){:target="_blank"}  
**リサーチアシスタント** @ [RebelsNLU](https://rebelsnlu.super.site/){:target="_blank"}, 指導教員: [井之上 直也 准教授](https://naoya-i.info/){:target="_blank"}   
{:.lang .lang-jp}

**別名**: Yufeng Zhao（漢字表記：「趙 羽風」）  
**生年**: 1999年, 北京生まれ  
{:.lang .lang-jp}

### 連絡先
{:.lang .lang-jp}

[Twitter](https://x.com/yfZhao495){:target="_blank"} &nbsp;&nbsp;&nbsp;
[GitHub](https://github.com/hc495){:target="_blank"} &nbsp;&nbsp;&nbsp; 
[OpenReview](https://openreview.net/profile?id=%7EHakaze_Cho1){:target="_blank"} &nbsp;&nbsp;&nbsp;
[ORCID](https://orcid.org/0000-0002-7127-1954){:target="_blank"} &nbsp;&nbsp;&nbsp;
[CV](./assets/cv_yfzhao.pdf){:target="_blank"}    
**住所**: 石川県能美市旭台1-1 北陸先端科学技術大学院大学 情報科学研究科 I棟 I-52室   
**E-mail**: yfzhao [at] jaist.ac.jp  
このメールアドレスは常に受信できるとは限りません. もし私から返信がない場合は、yfZhao495 [at] outlook.comにも併せて送ってみてください.  
{:.lang .lang-jp}

### 紹介
{:.lang .lang-jp}

私は中国のトップ大学である北京理工大学を卒業し, 2021年に化学の学士号, 2023年にソフトウェア工学の修士号を取得しました. 現在はJAISTにて博士課程に在籍しており, 2026年3月の早期修了を目指しています. 研究テーマは, 人工ニューラルネットワーク, 特にTransformerベースのニューラル言語モデルにおける訓練・推論中の内部挙動を, 数学的および表現学習の手法によって解明し, その理解に基づく性能向上を目指すものです. 2023年以降、この分野において30本以上の論文および研究発表を発信しており、その中にはICLRやNeurIPSといったトップカンファレンスに採択されたものも含まれます.
{:.lang .lang-jp}

**研究協力募集.** この研究分野に関心のある方との共同研究を積極的に募集しています. ご興味をお持ちの方は, ぜひお気軽にご連絡ください. 専門家だけでなく, 意欲と学習効率の高い初心者との協力も歓迎します. また, 他分野での共同研究についても柔軟に対応いたします.
{:.lang .lang-jp}

**仕事募集.** 2026年4月より開始するフルタイムの雇用契約をすでに締結しており, 客員および非常勤での職も歓迎いたします. あわせて, 2029年4月開始の准教授職を探しております.
{:.lang .lang-jp}

## 研究関心
{:.lang .lang-jp}

**キーワード**: 表現学習, 機械論的解釈可能性, 文脈内学習  
{:.lang .lang-jp}

- **人工ニューラルネットワークの解釈可能性**: 機械論的解釈可能性（特にTransformer）  
  [[ICLR 2025](https://openreview.net/forum?id=xizpnYNvQq){:target="_blank"}] [[NeurIPS 2025](https://openreview.net/forum?id=FIfjDqjV0B){:target="_blank"}] [[COLING 2025](https://aclanthology.org/2025.coling-main.708/){:target="_blank"}]
- **人工ニューラルネットワークの制御可能性**: 低リソースモデル改善 / 機械論的視点からのモデル制御  
  [[NAACL 2025](https://aclanthology.org/2025.naacl-long.278/){:target="_blank"}] [[BlackboxNLP 2025](https://aclanthology.org/2025.blackboxnlp-1.21/){:target="_blank"}] 
- **その他**: 多様体学習, 低数値精度ニューラルネットワーク, モデル訓練ダイナミクス  
  [[ArXiv](https://arxiv.org/abs/2509.20997){:target="_blank"}] [[ArXiv](https://arxiv.org/abs/2503.02142){:target="_blank"}]
{:.lang .lang-jp}

## 論文一覧
{:.lang .lang-jp}

[[Export Publication List as TXT](/subpages/export.html?action=exportPaper&lang=jp){:target="_blank"}] 
[[Google Scholar](https://scholar.google.com/citations?user=q_eQAcwAAAAJ){:target="_blank"}] 
[[Researchmap](https://researchmap.jp/hc495){:target="_blank"}] 
[[Semantic Scholar](https://www.semanticscholar.org/author/Hakaze-Cho/2304519017){:target="_blank"}] 
[[DBLP](https://dblp.org/pid/379/4520.html){:target="_blank"}]   
{% include_relative _includes/paper_statics.html %}
{:.lang .lang-jp}

### 国際会議
{:.lang .lang-jp}

{% include_relative _includes/paper_list_international_c_papers.html %}
{:.lang .lang-jp}

### プレプリント
{:.lang .lang-jp}

{% include_relative _includes/paper_list_pre_print_papers.html %}
{:.lang .lang-jp}

### 国内会議・ジャーナル・その他<br><span style="font-size:0.8em">(† = 国際会議論文の日本国内再録; 通常: 査読なし, ▲ = 査読あり)</span>
{:.lang .lang-jp}

{% include_relative _includes/paper_list_domestic_c_papers_jp.html %}
{:.lang .lang-jp}

### 学位論文
{:.lang .lang-jp}

1. **大規模言語モデルにおける文脈内学習のメカニズム的基盤**    
    Yufeng Zhao   
    博士論文 @ 北陸先端科学技術大学院大学, **2026**. 223 pages.
2. **Fine-tuning with Randomly Initialized Downstream Network: Finding a Stable Convex-loss Region in Parameter Space**    
    Yufeng Zhao   
    修士論文 - 評価A @ 北京理工大学, **2023**. 81 pages.
3. **Synthesis and Self-Assembly of Aggregation-induced Emission Compounds**   
   Yufeng Zhao   
   学士論文 @ 北京理工大学, **2021**. 52 pages.
{:.lang .lang-jp .wide_list}

## 履歴
{:.lang .lang-jp}

- **[基礎科学特別研究員](https://www.riken.jp/careers/programs/spdr/index.html){:target="_blank"}** (SPDR), (2026年4月) ～ (2029年3月)  
  [理化学研究所](https://aip.riken.jp/){:target="_blank"} [革新知能統合研究センター](https://www.riken.jp/research/labs/aip/){:target="_blank"} [自然言語理解チーム](https://aip.riken.jp/labs/goalorient_tech/nat_lang_understand/){:target="_blank"}  
  メンター: [乾 健太郎 教授](https://kentaro-inui.github.io/){:target="_blank"}
- **ポスドク研究員** (2026年4月) ～ (2029年3月)  
  [東北大学](https://www.tohoku.ac.jp/ja/){:target="_blank"} [東北大学 自然言語処理研究グループ](https://www.nlp.ecei.tohoku.ac.jp/about-us/members/){:target="_blank"}  
  メンター: [乾 健太郎 教授](https://kentaro-inui.github.io/){:target="_blank"}
- **博士（情報科学）** リサーチアシスタント, 2023年10月 ～ (2026年3月) (予定, 早期修了)  
  [北陸先端科学技術大学院大学](https://www.jaist.ac.jp/){:target="_blank"} [コンピューティング科学研究領域](https://www.jaist.ac.jp/areas/cs/){:target="_blank"}   
  指導教員: [井之上 直也 准教授](https://naoya-i.info/){:target="_blank"}
- **修士（ソフトウェア工学）** 2021年9月 ～ 2023年6月  
  [北京理工大学](https://cs.bit.edu.cn/){:target="_blank"} [情報科学技術研究科](https://cs.bit.edu.cn/){:target="_blank"}  
  指導教員: 趙 羽風 (自主研究)
- **学士（化学）** 2017年8月 ～ 2021年6月  
  [北京理工大学](https://cs.bit.edu.cn/){:target="_blank"} 基礎科学部 [材料科学・工学科](https://mse.bit.edu.cn/){:target="_blank"}  
  指導教員: [石 建兵 准教授](https://pure.bit.edu.cn/en/persons/jianbing-shi/){:target="_blank"}
{:.lang .lang-jp .wide_list}

## 学術活動
{:.lang .lang-jp}

### 論文査読
{:.lang .lang-jp}

{% include_relative data/review_list.md %}
{:.lang .lang-jp}

### 所属学会
{:.lang .lang-jp}

- 言語処理学会 学生会員
- 人工知能学会 学生会員
- Association for Computational Linguistics (ACL)
{:.lang .lang-jp}

### 競争的研究経費
{:.lang .lang-jp}

- **Principal Investigator**: 機械論的制御可能性に向けた大規模言語モデルの回路ベース編集   
  理化学研究所 基礎科学特別研究員研究経費, 2026年4月 ～ 2029年3月, 300万円.
{:.lang .lang-jp}

### 受賞歴
{:.lang .lang-jp}

- [優秀賞](https://anlp.jp/nlp2025/award.html#outstanding){:target="_blank"} @ 言語処理学会 第31回年次大会 (NLP2025, ANLP), 2025 (全765件中上位15件, 2.0%)  
- [若手奨励賞](https://sites.google.com/sig-nl.ipsj.or.jp/sig-nl/%E6%8E%88%E8%B3%9E/young#h.qq15e8v12s8d){:target="_blank"} @ 情報処理学会 第260回NL研究会 (SIG-NL260), 2024  
- [スポンサー賞 (SB Intuitions Awards)](https://www.anlp.jp/nlp2024/award.html){:target="_blank"} @ 言語処理学会 第30回年次大会 (NLP2024), 2024  
- 文部科学省外国人留学生学習奨励費 @ 文部科学省, 2023
- 優秀口頭発表賞 @ 2022年欧亜フロンティアコンピュータ科学技術国際会議  
- GPA向上賞 @ 北京理工大学, 2020
<small>2019年に健康状態のため多くの試験を欠席したため、2020年の通常のGPAは顕著な向上と見なされました</small>
- 北京理工大学 年間(GPA)優秀賞：2018, 2019, 2021, 2022, 2023  
- 一等賞 @ 第30回中国（高校）化学オリンピック. 2016.
- 二等賞 @ 第29回中国（高校）化学オリンピック. 2015.
{:.lang .lang-jp}